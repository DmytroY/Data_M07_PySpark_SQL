{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a51a7-c9e1-4e81-8a5c-b91743a57054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, sequence, explode, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089ddf7e-aab9-44c3-b60a-bb0a752cefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/18 18:11:46 WARN SSLSocketFactoryEx: Failed to load OpenSSL. Falling back to the JSSE default.\n",
      "23/11/18 18:11:47 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: abfss://data@styakovdwesteurope.dfs.core.windows.net/hotel-weather.\n",
      "HEAD https://styakovdwesteurope.dfs.core.windows.net/data?resource=filesystem&timeout=90\n",
      "StatusCode=403\n",
      "StatusDescription=Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\n",
      "ErrorCode=\n",
      "ErrorMessage=\n",
      "\tat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\n",
      "\tat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:197)\n",
      "\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getIsNamespaceEnabled(AzureBlobFileSystemStore.java:181)\n",
      "\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getFileStatus(AzureBlobFileSystemStore.java:454)\n",
      "\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.getFileStatus(AzureBlobFileSystem.java:395)\n",
      "\tat org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1777)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o41.parquet.\n: HEAD https://styakovdwesteurope.dfs.core.windows.net/data?resource=filesystem&timeout=90\nStatusCode=403\nStatusDescription=Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nErrorCode=\nErrorMessage=\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:197)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getIsNamespaceEnabled(AzureBlobFileSystemStore.java:181)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getFileStatus(AzureBlobFileSystemStore.java:454)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.getFileStatus(AzureBlobFileSystem.java:395)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:756)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:754)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_13913/3341833883.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabfss://data@styakovdwesteurope.dfs.core.windows.net\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m hw_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/hotel-weather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      3\u001b[0m ex_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload(data_path  \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/expedia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      4\u001b[0m hw_df\u001b[38;5;241m.\u001b[39mcreateOrReplaceTempView(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:544\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    533\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    535\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    536\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o41.parquet.\n: HEAD https://styakovdwesteurope.dfs.core.windows.net/data?resource=filesystem&timeout=90\nStatusCode=403\nStatusDescription=Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nErrorCode=\nErrorMessage=\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:197)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getIsNamespaceEnabled(AzureBlobFileSystemStore.java:181)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getFileStatus(AzureBlobFileSystemStore.java:454)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.getFileStatus(AzureBlobFileSystem.java:395)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:756)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:754)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o41.parquet.\n: HEAD https://styakovdwesteurope.dfs.core.windows.net/data?resource=filesystem&timeout=90\nStatusCode=403\nStatusDescription=Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nErrorCode=\nErrorMessage=\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:197)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getIsNamespaceEnabled(AzureBlobFileSystemStore.java:181)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getFileStatus(AzureBlobFileSystemStore.java:454)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.getFileStatus(AzureBlobFileSystem.java:395)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:756)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:754)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m01_setup.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2454\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2454\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:737\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 737\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2976\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   2974\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 2976\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:292\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_13913/3341833883.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabfss://data@styakovdwesteurope.dfs.core.windows.net\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m hw_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/hotel-weather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      3\u001b[0m ex_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload(data_path  \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/expedia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      4\u001b[0m hw_df\u001b[38;5;241m.\u001b[39mcreateOrReplaceTempView(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:544\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    533\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    535\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    536\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o41.parquet.\n: HEAD https://styakovdwesteurope.dfs.core.windows.net/data?resource=filesystem&timeout=90\nStatusCode=403\nStatusDescription=Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nErrorCode=\nErrorMessage=\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.execute(AbfsRestOperation.java:134)\n\tat org.apache.hadoop.fs.azurebfs.services.AbfsClient.getFilesystemProperties(AbfsClient.java:197)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getIsNamespaceEnabled(AzureBlobFileSystemStore.java:181)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore.getFileStatus(AzureBlobFileSystemStore.java:454)\n\tat org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem.getFileStatus(AzureBlobFileSystem.java:395)\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1760)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4(DataSource.scala:756)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$4$adapted(DataSource.scala:754)\n\tat org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:380)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n"
     ]
    }
   ],
   "source": [
    "%run 01_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86328b05-f2f3-4d5d-ba70-db95f61893c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ex_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# take only clear data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ex_clear \u001b[38;5;241m=\u001b[39m \u001b[43mex_df\u001b[49m\u001b[38;5;241m.\u001b[39mfilter(to_date(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_ci\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m to_date(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_co\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ex_df' is not defined"
     ]
    }
   ],
   "source": [
    "# take only clear data\n",
    "ex_clear = ex_df.filter(to_date(\"srch_ci\") <= to_date(\"srch_co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cede4fe2-897e-4c79-88ad-ff881216d9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "-- take only clear data\n",
    "CREATE OR REPLACE TEMP VIEW ex_clear AS\n",
    "    SELECT * FROM ex WHERE date(srch_ci) <= date(srch_co);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb50260d-0b6d-408f-a1ef-6f4c430e3bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr style=\"border-bottom: 1px solid\"></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sparksql\n",
    "-- sum booked rooms by dates\n",
    "CREATE OR REPLACE TEMP VIEW visits AS\n",
    "    WITH v AS (\n",
    "        SELECT \n",
    "            hotel_id,\n",
    "            explode(sequence(date(srch_ci),date(srch_co), INTERVAL 1 DAY)) AS date,\n",
    "            srch_rm_cnt\n",
    "        FROM ex_clear)\n",
    "    SELECT hotel_id, date, sum(srch_rm_cnt) AS used_rooms FROM v GROUP BY hotel_id, date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d82ecff-7a88-4b28-a404-220ad6e09dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ex_clear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#sum booked rooms by dates\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ex_df1 \u001b[38;5;241m=\u001b[39m \u001b[43mex_clear\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m, explode(sequence(to_date(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrch_ci\u001b[39m\u001b[38;5;124m'\u001b[39m),to_date(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrch_co\u001b[39m\u001b[38;5;124m'\u001b[39m)))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrch_rm_cnt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m visits_df \u001b[38;5;241m=\u001b[39m ex_df1\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrch_rm_cnt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_rooms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ex_clear' is not defined"
     ]
    }
   ],
   "source": [
    "#sum booked rooms by dates\n",
    "ex_df1 = ex_clear.select('hotel_id', explode(sequence(to_date('srch_ci'),to_date('srch_co'))).alias('date'), 'srch_rm_cnt')\n",
    "visits_df = ex_df1.groupBy('hotel_id', 'date').sum('srch_rm_cnt').alias('user_rooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea6b99e-ddd0-40eb-9aef-9d5cc14b910b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visits_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisits_df\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visits_df' is not defined"
     ]
    }
   ],
   "source": [
    "visits_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a5410-0b21-43ed-8b2b-bff70a5afb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_df = visits_df.select('hotel_id', 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "872ded78-9d35-4bf8-90e0-ff152092c098",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `ymCTE`.`year` cannot be resolved. Did you mean one of the following? [`visits`.`date`, `visits`.`hotel_id`, `visits`.`used_rooms`].; line 5 pos 17;\n'WithCTE\n:- CTERelationDef 18, false\n:  +- SubqueryAlias ymCTE\n:     +- Project [year#326 AS year#402, month#327 AS month#403]\n:        +- Distinct\n:           +- Project [year(date#331) AS year#326, month(date#331) AS month#327]\n:              +- SubqueryAlias visits\n:                 +- View (`visits`, [hotel_id#330L,date#331,used_rooms#332L])\n:                    +- Project [cast(hotel_id#352L as bigint) AS hotel_id#330L, cast(date#353 as date) AS date#331, cast(used_rooms#328L as bigint) AS used_rooms#332L]\n:                       +- WithCTE\n:                          :- CTERelationDef 19, false\n:                          :  +- SubqueryAlias v\n:                          :     +- Project [hotel_id#352L, date#353, srch_rm_cnt#349]\n:                          :        +- Generate explode(sequence(cast(srch_ci#345 as date), cast(srch_co#346 as date), Some(INTERVAL '1' DAY), Some(Europe/Kyiv))), false, [date#353]\n:                          :           +- SubqueryAlias ex_clear\n:                          :              +- View (`ex_clear`, [id#333L,date_time#334,site_name#335,posa_continent#336,user_location_country#337,user_location_region#338,user_location_city#339,orig_destination_distance#340,user_id#341,is_mobile#342,is_package#343,channel#344,srch_ci#345,srch_co#346,srch_adults_cnt#347,srch_children_cnt#348,srch_rm_cnt#349,srch_destination_id#350,srch_destination_type_id#351,hotel_id#352L])\n:                          :                 +- Project [cast(id#28L as bigint) AS id#333L, cast(date_time#29 as string) AS date_time#334, cast(site_name#30 as int) AS site_name#335, cast(posa_continent#31 as int) AS posa_continent#336, cast(user_location_country#32 as int) AS user_location_country#337, cast(user_location_region#33 as int) AS user_location_region#338, cast(user_location_city#34 as int) AS user_location_city#339, cast(orig_destination_distance#35 as double) AS orig_destination_distance#340, cast(user_id#36 as int) AS user_id#341, cast(is_mobile#37 as int) AS is_mobile#342, cast(is_package#38 as int) AS is_package#343, cast(channel#39 as int) AS channel#344, cast(srch_ci#40 as string) AS srch_ci#345, cast(srch_co#41 as string) AS srch_co#346, cast(srch_adults_cnt#42 as int) AS srch_adults_cnt#347, cast(srch_children_cnt#43 as int) AS srch_children_cnt#348, cast(srch_rm_cnt#44 as int) AS srch_rm_cnt#349, cast(srch_destination_id#45 as int) AS srch_destination_id#350, cast(srch_destination_type_id#46 as int) AS srch_destination_type_id#351, cast(hotel_id#47L as bigint) AS hotel_id#352L]\n:                          :                    +- Project [id#28L, date_time#29, site_name#30, posa_continent#31, user_location_country#32, user_location_region#33, user_location_city#34, orig_destination_distance#35, user_id#36, is_mobile#37, is_package#38, channel#39, srch_ci#40, srch_co#41, srch_adults_cnt#42, srch_children_cnt#43, srch_rm_cnt#44, srch_destination_id#45, srch_destination_type_id#46, hotel_id#47L]\n:                          :                       +- Filter (cast(srch_ci#40 as date) <= cast(srch_co#41 as date))\n:                          :                          +- SubqueryAlias ex\n:                          :                             +- View (`ex`, [id#28L,date_time#29,site_name#30,posa_continent#31,user_location_country#32,user_location_region#33,user_location_city#34,orig_destination_distance#35,user_id#36,is_mobile#37,is_package#38,channel#39,srch_ci#40,srch_co#41,srch_adults_cnt#42,srch_children_cnt#43,srch_rm_cnt#44,srch_destination_id#45,srch_destination_type_id#46,hotel_id#47L])\n:                          :                                +- GlobalLimit 1000\n:                          :                                   +- LocalLimit 1000\n:                          :                                      +- Relation [id#28L,date_time#29,site_name#30,posa_continent#31,user_location_country#32,user_location_region#33,user_location_city#34,orig_destination_distance#35,user_id#36,is_mobile#37,is_package#38,channel#39,srch_ci#40,srch_co#41,srch_adults_cnt#42,srch_children_cnt#43,srch_rm_cnt#44,srch_destination_id#45,srch_destination_type_id#46,hotel_id#47L] avro\n:                          +- Aggregate [hotel_id#352L, date#353], [hotel_id#352L, date#353, sum(srch_rm_cnt#349) AS used_rooms#328L]\n:                             +- SubqueryAlias v\n:                                +- CTERelationRef 19, true, [hotel_id#352L, date#353, srch_rm_cnt#349]\n+- 'GlobalLimit 10\n   +- 'LocalLimit 10\n      +- 'Project [hotel_id#357L, 'ymCTE.year, 'ymCTE.month]\n         +- SubqueryAlias visits\n            +- View (`visits`, [hotel_id#357L,date#358,used_rooms#359L])\n               +- Project [cast(hotel_id#379L as bigint) AS hotel_id#357L, cast(date#380 as date) AS date#358, cast(used_rooms#355L as bigint) AS used_rooms#359L]\n                  +- WithCTE\n                     :- CTERelationDef 20, false\n                     :  +- SubqueryAlias v\n                     :     +- Project [hotel_id#379L, date#380, srch_rm_cnt#376]\n                     :        +- Generate explode(sequence(cast(srch_ci#372 as date), cast(srch_co#373 as date), Some(INTERVAL '1' DAY), Some(Europe/Kyiv))), false, [date#380]\n                     :           +- SubqueryAlias ex_clear\n                     :              +- View (`ex_clear`, [id#360L,date_time#361,site_name#362,posa_continent#363,user_location_country#364,user_location_region#365,user_location_city#366,orig_destination_distance#367,user_id#368,is_mobile#369,is_package#370,channel#371,srch_ci#372,srch_co#373,srch_adults_cnt#374,srch_children_cnt#375,srch_rm_cnt#376,srch_destination_id#377,srch_destination_type_id#378,hotel_id#379L])\n                     :                 +- Project [cast(id#382L as bigint) AS id#360L, cast(date_time#383 as string) AS date_time#361, cast(site_name#384 as int) AS site_name#362, cast(posa_continent#385 as int) AS posa_continent#363, cast(user_location_country#386 as int) AS user_location_country#364, cast(user_location_region#387 as int) AS user_location_region#365, cast(user_location_city#388 as int) AS user_location_city#366, cast(orig_destination_distance#389 as double) AS orig_destination_distance#367, cast(user_id#390 as int) AS user_id#368, cast(is_mobile#391 as int) AS is_mobile#369, cast(is_package#392 as int) AS is_package#370, cast(channel#393 as int) AS channel#371, cast(srch_ci#394 as string) AS srch_ci#372, cast(srch_co#395 as string) AS srch_co#373, cast(srch_adults_cnt#396 as int) AS srch_adults_cnt#374, cast(srch_children_cnt#397 as int) AS srch_children_cnt#375, cast(srch_rm_cnt#398 as int) AS srch_rm_cnt#376, cast(srch_destination_id#399 as int) AS srch_destination_id#377, cast(srch_destination_type_id#400 as int) AS srch_destination_type_id#378, cast(hotel_id#401L as bigint) AS hotel_id#379L]\n                     :                    +- Project [id#382L, date_time#383, site_name#384, posa_continent#385, user_location_country#386, user_location_region#387, user_location_city#388, orig_destination_distance#389, user_id#390, is_mobile#391, is_package#392, channel#393, srch_ci#394, srch_co#395, srch_adults_cnt#396, srch_children_cnt#397, srch_rm_cnt#398, srch_destination_id#399, srch_destination_type_id#400, hotel_id#401L]\n                     :                       +- Filter (cast(srch_ci#394 as date) <= cast(srch_co#395 as date))\n                     :                          +- SubqueryAlias ex\n                     :                             +- View (`ex`, [id#382L,date_time#383,site_name#384,posa_continent#385,user_location_country#386,user_location_region#387,user_location_city#388,orig_destination_distance#389,user_id#390,is_mobile#391,is_package#392,channel#393,srch_ci#394,srch_co#395,srch_adults_cnt#396,srch_children_cnt#397,srch_rm_cnt#398,srch_destination_id#399,srch_destination_type_id#400,hotel_id#401L])\n                     :                                +- GlobalLimit 1000\n                     :                                   +- LocalLimit 1000\n                     :                                      +- Relation [id#382L,date_time#383,site_name#384,posa_continent#385,user_location_country#386,user_location_region#387,user_location_city#388,orig_destination_distance#389,user_id#390,is_mobile#391,is_package#392,channel#393,srch_ci#394,srch_co#395,srch_adults_cnt#396,srch_children_cnt#397,srch_rm_cnt#398,srch_destination_id#399,srch_destination_type_id#400,hotel_id#401L] avro\n                     +- Aggregate [hotel_id#379L, date#380], [hotel_id#379L, date#380, sum(srch_rm_cnt#376) AS used_rooms#355L]\n                        +- SubqueryAlias v\n                           +- CTERelationRef 20, true, [hotel_id#379L, date#380, srch_rm_cnt#376]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msparksql\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWITH ymCTE(year, month) AS (\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    SELECT DISTINCT year(date) AS year, month(date) AS month \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    FROM visits\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSELECT hotel_id, ymCTE.year, ymCTE.month FROM visits LIMIT 10\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2493\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2492\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2493\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sparksql_magic/sparksql.py:40\u001b[0m, in \u001b[0;36mSparkSql.sparksql\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive spark session is not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39meager:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache dataframe with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m load\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlazy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `ymCTE`.`year` cannot be resolved. Did you mean one of the following? [`visits`.`date`, `visits`.`hotel_id`, `visits`.`used_rooms`].; line 5 pos 17;\n'WithCTE\n:- CTERelationDef 18, false\n:  +- SubqueryAlias ymCTE\n:     +- Project [year#326 AS year#402, month#327 AS month#403]\n:        +- Distinct\n:           +- Project [year(date#331) AS year#326, month(date#331) AS month#327]\n:              +- SubqueryAlias visits\n:                 +- View (`visits`, [hotel_id#330L,date#331,used_rooms#332L])\n:                    +- Project [cast(hotel_id#352L as bigint) AS hotel_id#330L, cast(date#353 as date) AS date#331, cast(used_rooms#328L as bigint) AS used_rooms#332L]\n:                       +- WithCTE\n:                          :- CTERelationDef 19, false\n:                          :  +- SubqueryAlias v\n:                          :     +- Project [hotel_id#352L, date#353, srch_rm_cnt#349]\n:                          :        +- Generate explode(sequence(cast(srch_ci#345 as date), cast(srch_co#346 as date), Some(INTERVAL '1' DAY), Some(Europe/Kyiv))), false, [date#353]\n:                          :           +- SubqueryAlias ex_clear\n:                          :              +- View (`ex_clear`, [id#333L,date_time#334,site_name#335,posa_continent#336,user_location_country#337,user_location_region#338,user_location_city#339,orig_destination_distance#340,user_id#341,is_mobile#342,is_package#343,channel#344,srch_ci#345,srch_co#346,srch_adults_cnt#347,srch_children_cnt#348,srch_rm_cnt#349,srch_destination_id#350,srch_destination_type_id#351,hotel_id#352L])\n:                          :                 +- Project [cast(id#28L as bigint) AS id#333L, cast(date_time#29 as string) AS date_time#334, cast(site_name#30 as int) AS site_name#335, cast(posa_continent#31 as int) AS posa_continent#336, cast(user_location_country#32 as int) AS user_location_country#337, cast(user_location_region#33 as int) AS user_location_region#338, cast(user_location_city#34 as int) AS user_location_city#339, cast(orig_destination_distance#35 as double) AS orig_destination_distance#340, cast(user_id#36 as int) AS user_id#341, cast(is_mobile#37 as int) AS is_mobile#342, cast(is_package#38 as int) AS is_package#343, cast(channel#39 as int) AS channel#344, cast(srch_ci#40 as string) AS srch_ci#345, cast(srch_co#41 as string) AS srch_co#346, cast(srch_adults_cnt#42 as int) AS srch_adults_cnt#347, cast(srch_children_cnt#43 as int) AS srch_children_cnt#348, cast(srch_rm_cnt#44 as int) AS srch_rm_cnt#349, cast(srch_destination_id#45 as int) AS srch_destination_id#350, cast(srch_destination_type_id#46 as int) AS srch_destination_type_id#351, cast(hotel_id#47L as bigint) AS hotel_id#352L]\n:                          :                    +- Project [id#28L, date_time#29, site_name#30, posa_continent#31, user_location_country#32, user_location_region#33, user_location_city#34, orig_destination_distance#35, user_id#36, is_mobile#37, is_package#38, channel#39, srch_ci#40, srch_co#41, srch_adults_cnt#42, srch_children_cnt#43, srch_rm_cnt#44, srch_destination_id#45, srch_destination_type_id#46, hotel_id#47L]\n:                          :                       +- Filter (cast(srch_ci#40 as date) <= cast(srch_co#41 as date))\n:                          :                          +- SubqueryAlias ex\n:                          :                             +- View (`ex`, [id#28L,date_time#29,site_name#30,posa_continent#31,user_location_country#32,user_location_region#33,user_location_city#34,orig_destination_distance#35,user_id#36,is_mobile#37,is_package#38,channel#39,srch_ci#40,srch_co#41,srch_adults_cnt#42,srch_children_cnt#43,srch_rm_cnt#44,srch_destination_id#45,srch_destination_type_id#46,hotel_id#47L])\n:                          :                                +- GlobalLimit 1000\n:                          :                                   +- LocalLimit 1000\n:                          :                                      +- Relation [id#28L,date_time#29,site_name#30,posa_continent#31,user_location_country#32,user_location_region#33,user_location_city#34,orig_destination_distance#35,user_id#36,is_mobile#37,is_package#38,channel#39,srch_ci#40,srch_co#41,srch_adults_cnt#42,srch_children_cnt#43,srch_rm_cnt#44,srch_destination_id#45,srch_destination_type_id#46,hotel_id#47L] avro\n:                          +- Aggregate [hotel_id#352L, date#353], [hotel_id#352L, date#353, sum(srch_rm_cnt#349) AS used_rooms#328L]\n:                             +- SubqueryAlias v\n:                                +- CTERelationRef 19, true, [hotel_id#352L, date#353, srch_rm_cnt#349]\n+- 'GlobalLimit 10\n   +- 'LocalLimit 10\n      +- 'Project [hotel_id#357L, 'ymCTE.year, 'ymCTE.month]\n         +- SubqueryAlias visits\n            +- View (`visits`, [hotel_id#357L,date#358,used_rooms#359L])\n               +- Project [cast(hotel_id#379L as bigint) AS hotel_id#357L, cast(date#380 as date) AS date#358, cast(used_rooms#355L as bigint) AS used_rooms#359L]\n                  +- WithCTE\n                     :- CTERelationDef 20, false\n                     :  +- SubqueryAlias v\n                     :     +- Project [hotel_id#379L, date#380, srch_rm_cnt#376]\n                     :        +- Generate explode(sequence(cast(srch_ci#372 as date), cast(srch_co#373 as date), Some(INTERVAL '1' DAY), Some(Europe/Kyiv))), false, [date#380]\n                     :           +- SubqueryAlias ex_clear\n                     :              +- View (`ex_clear`, [id#360L,date_time#361,site_name#362,posa_continent#363,user_location_country#364,user_location_region#365,user_location_city#366,orig_destination_distance#367,user_id#368,is_mobile#369,is_package#370,channel#371,srch_ci#372,srch_co#373,srch_adults_cnt#374,srch_children_cnt#375,srch_rm_cnt#376,srch_destination_id#377,srch_destination_type_id#378,hotel_id#379L])\n                     :                 +- Project [cast(id#382L as bigint) AS id#360L, cast(date_time#383 as string) AS date_time#361, cast(site_name#384 as int) AS site_name#362, cast(posa_continent#385 as int) AS posa_continent#363, cast(user_location_country#386 as int) AS user_location_country#364, cast(user_location_region#387 as int) AS user_location_region#365, cast(user_location_city#388 as int) AS user_location_city#366, cast(orig_destination_distance#389 as double) AS orig_destination_distance#367, cast(user_id#390 as int) AS user_id#368, cast(is_mobile#391 as int) AS is_mobile#369, cast(is_package#392 as int) AS is_package#370, cast(channel#393 as int) AS channel#371, cast(srch_ci#394 as string) AS srch_ci#372, cast(srch_co#395 as string) AS srch_co#373, cast(srch_adults_cnt#396 as int) AS srch_adults_cnt#374, cast(srch_children_cnt#397 as int) AS srch_children_cnt#375, cast(srch_rm_cnt#398 as int) AS srch_rm_cnt#376, cast(srch_destination_id#399 as int) AS srch_destination_id#377, cast(srch_destination_type_id#400 as int) AS srch_destination_type_id#378, cast(hotel_id#401L as bigint) AS hotel_id#379L]\n                     :                    +- Project [id#382L, date_time#383, site_name#384, posa_continent#385, user_location_country#386, user_location_region#387, user_location_city#388, orig_destination_distance#389, user_id#390, is_mobile#391, is_package#392, channel#393, srch_ci#394, srch_co#395, srch_adults_cnt#396, srch_children_cnt#397, srch_rm_cnt#398, srch_destination_id#399, srch_destination_type_id#400, hotel_id#401L]\n                     :                       +- Filter (cast(srch_ci#394 as date) <= cast(srch_co#395 as date))\n                     :                          +- SubqueryAlias ex\n                     :                             +- View (`ex`, [id#382L,date_time#383,site_name#384,posa_continent#385,user_location_country#386,user_location_region#387,user_location_city#388,orig_destination_distance#389,user_id#390,is_mobile#391,is_package#392,channel#393,srch_ci#394,srch_co#395,srch_adults_cnt#396,srch_children_cnt#397,srch_rm_cnt#398,srch_destination_id#399,srch_destination_type_id#400,hotel_id#401L])\n                     :                                +- GlobalLimit 1000\n                     :                                   +- LocalLimit 1000\n                     :                                      +- Relation [id#382L,date_time#383,site_name#384,posa_continent#385,user_location_country#386,user_location_region#387,user_location_city#388,orig_destination_distance#389,user_id#390,is_mobile#391,is_package#392,channel#393,srch_ci#394,srch_co#395,srch_adults_cnt#396,srch_children_cnt#397,srch_rm_cnt#398,srch_destination_id#399,srch_destination_type_id#400,hotel_id#401L] avro\n                     +- Aggregate [hotel_id#379L, date#380], [hotel_id#379L, date#380, sum(srch_rm_cnt#376) AS used_rooms#355L]\n                        +- SubqueryAlias v\n                           +- CTERelationRef 20, true, [hotel_id#379L, date#380, srch_rm_cnt#376]\n"
     ]
    }
   ],
   "source": [
    "%%sparksql\n",
    "WITH ymCTE(year, month) AS (\n",
    "    SELECT DISTINCT year(date) AS year, month(date) AS month \n",
    "    FROM visits\n",
    ")\n",
    "SELECT hotel_id, ymCTE.year, ymCTE.month FROM visits LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc7f316d-8dbf-4c2e-8784-fed86b32e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[hotel_id#47L, date#613], functions=[sum(srch_rm_cnt#44)])\n",
      "   +- HashAggregate(keys=[hotel_id#47L, date#613], functions=[partial_sum(srch_rm_cnt#44)])\n",
      "      +- Project [hotel_id#47L, date#613, srch_rm_cnt#44]\n",
      "         +- Generate explode(sequence(cast(srch_ci#40 as date), cast(srch_co#41 as date), Some(INTERVAL '1' DAY), Some(Europe/Kyiv))), [srch_rm_cnt#44, hotel_id#47L], false, [date#613]\n",
      "            +- Filter ((isnotnull(srch_ci#40) AND isnotnull(srch_co#41)) AND (cast(srch_ci#40 as date) <= cast(srch_co#41 as date)))\n",
      "               +- GlobalLimit 1000, 0\n",
      "                  +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=1268]\n",
      "                     +- LocalLimit 1000\n",
      "                        +- FileScan avro [srch_ci#40,srch_co#41,srch_rm_cnt#44,hotel_id#47L] Batched: false, DataFilters: [], Format: Avro, Location: InMemoryFileIndex(1 paths)[abfss://data@styakovdwesteurope.dfs.core.windows.net/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<srch_ci:string,srch_co:string,srch_rm_cnt:int,hotel_id:bigint>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM visits\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb47e44-60d8-46a4-bffd-75e1e3da585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "CREATE OR REPLACE TEMPORARY VIEW hwp AS\n",
    "    SELECT /*+ BROADCAST(periods) */ * FROM periods JOIN hw ON TRUE;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
